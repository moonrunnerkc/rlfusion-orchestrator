# Author: Bradley R. Kinnard
# docker-compose.yml - CPU and GPU profiles for RLFusion (2-path architecture)
# Usage: docker compose --profile cpu up
#        docker compose --profile gpu up
# Models must be pre-downloaded to models/ before first run.

services:
  backend-cpu:
    build:
      context: .
      dockerfile: Dockerfile
    profiles: ["cpu"]
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./db:/app/db
      - ./models:/app/models
    environment:
      - CUDA_VISIBLE_DEVICES=""
      - INFERENCE_ENGINE=llama_cpp_dual
    command: python3 -m uvicorn backend.main:app --host 0.0.0.0 --port 8000

  backend-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    profiles: ["gpu"]
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./db:/app/db
      - ./models:/app/models
    environment:
      - INFERENCE_ENGINE=llama_cpp_dual
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 24G
    command: python3 -m uvicorn backend.main:app --host 0.0.0.0 --port 8000

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    profiles: ["cpu", "gpu"]
    ports:
      - "5173:5173"
    command: npm run dev -- --host
